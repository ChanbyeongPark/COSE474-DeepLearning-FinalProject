{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FrabPBeWxzLg"},"outputs":[],"source":["# Based on https://github.com/weiaicunzai/pytorch-cifar100\n","# and https://github.com/junyuseu/pytorch-cifar-models/tree/master"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"OgbUgWRcwlm6","executionInfo":{"status":"ok","timestamp":1702034572483,"user_tz":-540,"elapsed":9164,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["import time\n","import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch.utils.data import DataLoader\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"KH2k_ysdBGZG"},"source":["# Models"]},{"cell_type":"markdown","metadata":{"id":"bYpUdNDmBLCi"},"source":["## Baseline Module"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VZdkjYWzvSxG","executionInfo":{"status":"ok","timestamp":1702034572484,"user_tz":-540,"elapsed":11,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["class PreActBasic(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_channels, out_channels, stride):\n","        super(PreActBasic, self).__init__()\n","\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels*self.expansion, 3, padding=1, bias=False)\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels * self.expansion:\n","            self.shortcut = nn.Conv2d(in_channels, out_channels * self.expansion, 1, stride=stride, bias=False)\n","\n","    def forward(self, x):\n","        res = self.residual(x)\n","        mapping = self.shortcut(x)\n","\n","        return res + mapping"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5-VvHw-Cwy0Z","executionInfo":{"status":"ok","timestamp":1702034572484,"user_tz":-540,"elapsed":10,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["class PreActBottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_channels, out_channels, stride):\n","        super(PreActBottleneck, self).__init__()\n","\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels * self.expansion, 1, bias=False)\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels * self.expansion:\n","            self.shortcut = nn.Conv2d(in_channels, out_channels * self.expansion, 1, stride=stride, bias=False)\n","\n","    def forward(self, x):\n","        res = self.residual(x)\n","        mapping = self.shortcut(x)\n","\n","        return res + mapping"]},{"cell_type":"markdown","metadata":{"id":"VNHzwAUMBVtg"},"source":["## ReLU Dropped Module"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6a3v0YyAILtd","executionInfo":{"status":"ok","timestamp":1702034572484,"user_tz":-540,"elapsed":9,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["class ReLUDroppedBasic(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_channels, out_channels, stride):\n","        super(ReLUDroppedBasic, self).__init__()\n","\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels*self.expansion, 3, padding=1, bias=False)\n","        )\n","\n","        self.reludrop = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels*self.expansion, 3, padding=1, bias=False)\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels * self.expansion:\n","            self.shortcut = nn.Conv2d(in_channels, out_channels * self.expansion, 1, stride=stride, bias=False)\n","\n","    def forward(self, x):\n","        res = self.residual(x)\n","        reludropres = self.reludrop(x)\n","        mapping = self.shortcut(x)\n","\n","        return res + reludropres + mapping"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"XIpHUU6aJckf","executionInfo":{"status":"ok","timestamp":1702034572485,"user_tz":-540,"elapsed":10,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["class ReLUDroppedBottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_channels, out_channels, stride):\n","        super(ReLUDroppedBottleneck, self).__init__()\n","\n","        self.residual = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels * self.expansion, 1, bias=False)\n","        )\n","\n","        self.reludrop = nn.Sequential(\n","            nn.BatchNorm2d(in_channels),\n","            nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels * self.expansion, 1, bias=False)\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels * self.expansion:\n","            self.shortcut = nn.Conv2d(in_channels, out_channels * self.expansion, 1, stride=stride, bias=False)\n","\n","    def forward(self, x):\n","        res = self.residual(x)\n","        reludropres = self.reludrop(x)\n","        mapping = self.shortcut(x)\n","\n","        return res + reludropres + mapping"]},{"cell_type":"markdown","metadata":{"id":"CY835ogWKqzm"},"source":["## Network Definition"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"g8AQMgl0z1Gk","executionInfo":{"status":"ok","timestamp":1702034572485,"user_tz":-540,"elapsed":9,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["class PreActResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=100):\n","        super(PreActResNet, self).__init__()\n","        self.input_channels = 16\n","\n","        self.pre = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.stage1 = self._make_layers(block, num_block[0], 16, 1)\n","        self.stage2 = self._make_layers(block, num_block[1], 32, 2)\n","        self.stage3 = self._make_layers(block, num_block[2], 64, 2)\n","\n","        self.finalact = nn.Sequential(\n","            nn.BatchNorm2d(64*block.expansion),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.linear = nn.Linear(64*block.expansion, num_classes)\n","\n","    def _make_layers(self, block, block_num, out_channels, stride):\n","        strides = [stride] + [1]*(block_num-1)\n","        layers = []\n","\n","        for stride in strides:\n","            layers.append(block(self.input_channels, out_channels, stride))\n","            self.input_channels = out_channels * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.pre(x)\n","\n","        x = self.stage1(x)\n","        x = self.stage2(x)\n","        x = self.stage3(x)\n","        x = self.finalact(x)\n","\n","        x = F.avg_pool2d(x, 8)\n","        x = x.view(x.size(0), -1)\n","        x = self.linear(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4elVAF_bLe1w","executionInfo":{"status":"ok","timestamp":1702034572485,"user_tz":-540,"elapsed":8,"user":{"displayName":"박찬병","userId":"13727339486715329378"}}},"outputs":[],"source":["def basicresnet110(num_classes=10):\n","    return PreActResNet(PreActBasic, [18, 18, 18], num_classes)\n","\n","def bottleneckresnet164(num_classes=10):\n","    return PreActResNet(PreActBottleneck, [18, 18, 18], num_classes)\n","\n","def basicresnet56_reludrop(num_classes=10):\n","    return PreActResNet(ReLUDroppedBasic, [9, 9, 9], num_classes)\n","\n","def bottleneckresnet83_reludrop(num_classes=10):\n","    return PreActResNet(ReLUDroppedBottleneck, [9, 9, 9], num_classes)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"X9G0kyw_O-RS","executionInfo":{"status":"ok","timestamp":1702034573279,"user_tz":-540,"elapsed":449,"user":{"displayName":"박찬병","userId":"13727339486715329378"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd3c5721-8bfc-4fd9-ee80-a1eed057d102"},"outputs":[{"output_type":"stream","name":"stdout","text":["1730554\n","1703290\n","1707418\n","1691802\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(count_parameters(basicresnet110(10)))\n","print(count_parameters(bottleneckresnet164(10)))\n","print(count_parameters(basicresnet56_reludrop(10)))\n","print(count_parameters(bottleneckresnet83_reludrop(10)))"]},{"cell_type":"markdown","metadata":{"id":"pUJEvz5oBf4q"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEwhNisd-9ko"},"outputs":[],"source":["def get_train_dataloader(mean, std, batch_size=128, num_classes=10, num_workers=4, shuffle=True):\n","    transform_train = transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","\n","    if num_classes == 100:\n","        cifar100_train = torchvision.datasets.CIFAR100(\n","            root='./data', train=True, download=True, transform=transform_train)\n","        cifar100_train_loader = DataLoader(\n","            cifar100_train, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n","        return cifar100_train_loader\n","\n","    if num_classes == 10:\n","        cifar10_train = torchvision.datasets.CIFAR10(\n","            root='./data', train=True, download=True, transform=transform_train)\n","        cifar10_train_loader = DataLoader(\n","            cifar10_train, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n","        return cifar10_train_loader\n","\n","def get_test_dataloader(mean, std, batch_size=100, num_classes=10, num_workers=4, shuffle=False):\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ])\n","\n","    if num_classes == 100:\n","        cifar100_test = torchvision.datasets.CIFAR100(\n","            root='./data', train=False, download=True, transform=transform_test)\n","        cifar100_test_loader = DataLoader(\n","            cifar100_test, shuffle=shuffle, num_workers = num_workers, batch_size=100)\n","        return cifar100_test_loader\n","\n","    if num_classes == 10:\n","        cifar10_test = torchvision.datasets.CIFAR10(\n","            root='./data', train=False, download=True, transform=transform_test)\n","        cifar10_test_loader = DataLoader(\n","            cifar10_test, shuffle=shuffle, num_workers = num_workers, batch_size=100)\n","        return cifar10_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgRrUbpP-0d7"},"outputs":[],"source":["# https://github.com/Armour/pytorch-nn-practice/blob/master/utils/meanstd.py\n","\n","def compute_mean_std(num_classes=10):\n","    mean = [0.49139968, 0.48215841, 0.44653091]\n","    std = [0.24703223, 0.24348513, 0.26158784]\n","\n","    if num_classes == 100:\n","        mean = [0.50707516, 0.48654887, 0.44091784]\n","        std = [0.26733429, 0.25643846, 0.27615047]\n","\n","    return mean, std"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZL9YBygbkfM"},"outputs":[],"source":["def lr_schedule(epoch):\n","    if epoch < 1:\n","        return 0.1\n","    elif epoch < 80:\n","        return 1\n","    elif epoch < 120:\n","        return 0.1 ** 1\n","    else:\n","        return 0.1 ** 2"]},{"cell_type":"markdown","metadata":{"id":"m15Q4zF7ZYff"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZMzqrS2SqQm"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ToyCT4DPUv2D"},"outputs":[],"source":["def modelload():\n","    num_classes = 10\n","\n","    # net = basicresnet110(num_classes=num_classes).to(device)\n","    # net = bottleneckresnet164(num_classes=num_classes).to(device)\n","    net = basicresnet56_reludrop(num_classes=num_classes).to(device)\n","    # net = bottleneckresnet83_reludrop(num_classes=num_classes).to(device)\n","\n","    return num_classes, net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9Fw5Si_bHkM"},"outputs":[],"source":["def utilload():\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","    scheduler = LambdaLR(optimizer, lr_lambda = lr_schedule)\n","\n","    batch_size = 128\n","    num_epochs = 165\n","\n","    return criterion, optimizer, scheduler, batch_size, num_epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOwnIEa8zjmR"},"outputs":[],"source":["def dataload():\n","    mean, std = compute_mean_std(num_classes)\n","    cifar_train_loader = get_train_dataloader(mean, std, batch_size, num_classes)\n","    cifar_test_loader = get_test_dataloader(mean, std, 100, num_classes)\n","\n","    return cifar_train_loader, cifar_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuGwhzitZZeV"},"outputs":[],"source":["def train(epoch):\n","    start = time.time()\n","    net.train()\n","    train_loss = 0.0\n","    train_correct = 0.0\n","    for batch_index, (images, labels) in tqdm.tqdm(enumerate(cifar_train_loader)):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, preds = outputs.max(1)\n","        train_correct += preds.eq(labels).sum()\n","\n","        # print('Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.6f}'.format(\n","        #     loss.item(),\n","        #     optimizer.param_groups[0]['lr'],\n","        #     epoch=epoch,\n","        #     trained_samples=batch_index * batch_size + len(images),\n","        #     total_samples=len(cifar_train_loader.dataset)\n","        # ))\n","\n","    finish = time.time()\n","\n","    train_error = 1 - train_correct.float().item() / len(cifar_train_loader.dataset)\n","\n","    print()\n","    print('Training epoch: {}, LR: {:.6f}, Average loss: {:.4f}, Error: {:.4f}, Time consumed: {:.2f}s'.format(\n","        epoch,\n","        optimizer.param_groups[0]['lr'],\n","        train_loss / len(cifar_train_loader.dataset),\n","        train_error,\n","        finish - start\n","    ))\n","\n","    return train_error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afj7POlIfEgj"},"outputs":[],"source":["def test(epoch):\n","    net.eval()\n","\n","    test_correct_1 = 0.0\n","    test_correct_5 = 0.0\n","\n","    with torch.no_grad():\n","        for batch_index, (images, labels) in enumerate(cifar_test_loader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = net(images)\n","            _, preds = outputs.topk(5, 1, largest=True, sorted=True)\n","\n","            labels = labels.view(labels.size(0), -1).expand_as(preds)\n","            correct = preds.eq(labels).float()\n","\n","            test_correct_5 += correct[:, :5].sum()\n","            test_correct_1 += correct[:, :1].sum()\n","\n","            test_top1_error = 1 - test_correct_1.item() / len(cifar_test_loader.dataset)\n","            test_top5_error = 1 - test_correct_5.item() / len(cifar_test_loader.dataset)\n","\n","    print(\"Test\")\n","    print(\"Top 1 err: {:.4f}\".format(test_top1_error))\n","    print(\"Top 5 err: {:.4f}\".format(test_top5_error))\n","\n","    return test_top1_error, test_top5_error"]},{"cell_type":"code","source":["for order in range(3):\n","    print(order)\n","\n","    num_classes, net = modelload()\n","    criterion, optimizer, scheduler, batch_size, num_epochs = utilload()\n","    cifar_train_loader, cifar_test_loader = dataload()\n","\n","    RDMResNet56_Train_CIFAR10 = []\n","    RDMResNet56_TestTop1_CIFAR10 = []\n","    RDMResNet56_TestTop5_CIFAR10 = []\n","\n","    for epoch in range(num_epochs):\n","        train_error = train(epoch)\n","        test_top1_error, test_top5_error = test(epoch)\n","\n","        RDMResNet56_Train_CIFAR10.append(str(train_error))\n","        RDMResNet56_TestTop1_CIFAR10.append(str(test_top1_error))\n","        RDMResNet56_TestTop5_CIFAR10.append(str(test_top5_error))\n","\n","        scheduler.step()\n","\n","    with open(f\"RDMResNet56 TrainingError CIFAR10 order{order}.txt\", \"w\") as file1:\n","        file1.write('\\n'.join(RDMResNet56_Train_CIFAR10))\n","\n","    with open(f\"RDMResNet56 TestError-Top1 CIFAR10 order{order}.txt\", \"w\") as file2:\n","        file2.write('\\n'.join(RDMResNet56_TestTop1_CIFAR10))\n","\n","    with open(f\"RDMResNet56 TestError-Top5 CIFAR10 order{order}.txt\", \"w\") as file3:\n","        file3.write('\\n'.join(RDMResNet56_TestTop5_CIFAR10))"],"metadata":{"id":"yfgGDqIln-z_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1cYOMiItSRVz7GPAhBDUvy547Fc6ky1Ra","timestamp":1701746923120}],"authorship_tag":"ABX9TyObLenWzaoP0CJ/FwAeROLn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}